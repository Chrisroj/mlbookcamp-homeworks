{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b8b7a9-07cd-429c-8e64-6465af241403",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly. That's fine. \n",
    "Select the option that's closest to your solution.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we will use the California Housing Prices data from [Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices).\n",
    "\n",
    "Here's a wget-able [link](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv):\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n",
    "```\n",
    "We'll keep working with the `'median_house_value'` variable, and we'll transform it to a classification task. \n",
    " \n",
    "\n",
    "### Features\n",
    "\n",
    "For the rest of the homework, you'll need to use only these columns:\n",
    "\n",
    "* `'latitude'`,\n",
    "* `'longitude'`,\n",
    "* `'housing_median_age'`,\n",
    "* `'total_rooms'`,\n",
    "* `'total_bedrooms'`,\n",
    "* `'population'`,\n",
    "* `'households'`,\n",
    "* `'median_income'`,\n",
    "* `'median_house_value'`,\n",
    "* `'ocean_proximity'`,\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Select only the features from above and fill in the missing values with 0.\n",
    "* Create a new column `rooms_per_household` by dividing the column `total_rooms` by the column `households` from dataframe. \n",
    "* Create a new column `bedrooms_per_room` by dividing the column `total_bedrooms` by the column `total_rooms` from dataframe. \n",
    "* Create a new column `population_per_household` by dividing the column `population` by the column `households` from dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5da77d-d958-481a-9873-bb65506388e7",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `ocean_proximity`?\n",
    "\n",
    "Options:\n",
    "* `NEAR BAY`\n",
    "* **`<1H OCEAN`**\n",
    "* `INLAND`\n",
    "* `NEAR OCEAN`\n",
    "\n",
    "\n",
    "## Split the data\n",
    "\n",
    "* Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to 42.\n",
    "* Make sure that the target value (`median_house_value`) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a036445-a94d-4986-b12a-c822a906f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "root = os.getcwd()\n",
    "housing_path = os.path.join(root, \"data\", \"housing.csv\")\n",
    "\n",
    "# Read Data\n",
    "housing = pd.read_csv(housing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3fff06-f583-49aa-a8a7-4612cbccd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Columns\n",
    "selected_columns = ['latitude',\n",
    "                    'longitude',\n",
    "                    'housing_median_age',\n",
    "                    'total_rooms',\n",
    "                    'total_bedrooms',\n",
    "                    'population',\n",
    "                    'households',\n",
    "                    'median_income',\n",
    "                    'median_house_value',\n",
    "                    'ocean_proximity']\n",
    "housing = housing[selected_columns].fillna(0).copy()\n",
    "\n",
    "# FE\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"] = housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3eb393-bc36-40ca-8489-bdaeaf96b0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <1H OCEAN\n",
       "Name: ocean_proximity, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mode\n",
    "housing[\"ocean_proximity\"].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b0b15a-f9b2-4206-9c21-40fa1a9712ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "df = housing.copy()\n",
    "df_train_full, df_test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size = 0.25, random_state = 42)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.median_house_value\n",
    "y_val = df_val.median_house_value\n",
    "y_test = df_test.median_house_value\n",
    "\n",
    "del df_train['median_house_value']\n",
    "del df_val['median_house_value']\n",
    "del df_test['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d04dd-bfcf-41bf-b1d0-ea5a4343c591",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "* Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your train dataset.\n",
    "    - In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "* What are the two features that have the biggest correlation in this dataset?\n",
    "\n",
    "Options:\n",
    "* **`total_bedrooms` and `households`**\n",
    "* `total_bedrooms` and `total_rooms`\n",
    "* `population` and `households`\n",
    "* `population_per_household` and `total_rooms`\n",
    "\n",
    "\n",
    "### Make `median_house_value` binary\n",
    "\n",
    "* We need to turn the `median_house_value` variable from numeric into binary.\n",
    "* Let's create a variable `above_average` which is `1` if the `median_house_value` is above its mean value and `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e65be2-db11-4072-b632-241736087858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_corr_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    import numpy as np\n",
    "    \n",
    "    # Get Numpy Array\n",
    "    array = df.values.copy()\n",
    "    n_variables = array.shape[0]\n",
    "    variables_names = df.columns\n",
    "\n",
    "    # Get Indices of Lower Triangule Matrix\n",
    "    iu2 = np.triu_indices(n_variables)\n",
    "\n",
    "    # Drop Upper Triangule Matrix\n",
    "    array[iu2] = 9999\n",
    "    corr_mat = pd.DataFrame(array, index = variables_names, columns = variables_names)\n",
    "    corr_mat = corr_mat.stack().reset_index()\n",
    "    corr_mat.columns = ['variable_1','variable_2','r']\n",
    "    corr_mat = corr_mat.query(\"r != 9999\")\n",
    "    \n",
    "    # Abs of Correlation\n",
    "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
    "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
    "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
    "    \n",
    "    return corr_mat.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b08bf1-992e-481a-b500-012bb0a96216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_1</th>\n",
       "      <th>variable_2</th>\n",
       "      <th>r</th>\n",
       "      <th>abs_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>households</td>\n",
       "      <td>total_bedrooms</td>\n",
       "      <td>0.979399</td>\n",
       "      <td>0.979399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable_1      variable_2         r     abs_r\n",
       "0  households  total_bedrooms  0.979399  0.979399"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_corr_matrix(df_train.corr()).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e28eb4-bc4a-453e-9262-68cabb346c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarized median_house_value\n",
    "mean_target_train = y_train.mean()\n",
    "\n",
    "y_train_binarized = y_train.apply(lambda x: 1 if x > mean_target_train else 0)\n",
    "y_val_binarized = y_val.apply(lambda x: 1 if x > mean_target_train else 0)\n",
    "y_test_binarized = y_test.apply(lambda x: 1 if x > mean_target_train else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59dc7fb-2de5-49a7-a123-05d753e74e8e",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "* Calculate the mutual information score with the (binarized) price for the categorical variable that we have. Use the training set only.\n",
    "* What is the value of mutual information?\n",
    "* Round it to 2 decimal digits using `round(score, 2)`\n",
    "\n",
    "Options:\n",
    "- 0.26\n",
    "- 0\n",
    "- **0.10**\n",
    "- 0.16\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684b9ad7-019b-450c-8127-b6bf880931d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931f98b6-7cf5-46ed-ac22-d8128c442642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info = mutual_info_score(df_train.ocean_proximity, y_train_binarized)\n",
    "round(mutual_info, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe148e9f-b726-4628-8adf-d4034798192c",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "* Now let's train a logistic regression\n",
    "* Remember that we have one categorical variable `ocean_proximity` in the data. Include it using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - `model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)`\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "Options:\n",
    "- 0.60\n",
    "- 0.72\n",
    "- **0.84**\n",
    "- 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb596b01-f8f4-4e46-b153-1784a699f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Train\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_cat = ohe.fit_transform(df_train[[\"ocean_proximity\"]].values)\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns = ohe.get_feature_names_out().tolist())\n",
    "X_train = pd.concat([df_train, X_train_cat], axis = 1).drop(\"ocean_proximity\", axis = 1)\n",
    "\n",
    "# Val\n",
    "X_val_cat = ohe.transform(df_val[[\"ocean_proximity\"]].values)\n",
    "X_val_cat = pd.DataFrame(X_val_cat, columns = ohe.get_feature_names_out().tolist())\n",
    "X_val = pd.concat([df_val, X_val_cat], axis = 1).drop(\"ocean_proximity\", axis = 1)\n",
    "\n",
    "# Test\n",
    "X_test_cat = ohe.transform(df_test[[\"ocean_proximity\"]].values)\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns = ohe.get_feature_names_out().tolist())\n",
    "X_test = pd.concat([df_test, X_test_cat], axis = 1).drop(\"ocean_proximity\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29fb7709-abee-4387-adb0-3e05c327f298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e37d31c6-8119-47df-b2ea-dff01d77bbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = model.predict(X_val)\n",
    "acc = accuracy_score(y_val_binarized, y_val_predicted)\n",
    "round(acc, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effbec79-a298-4e49-ac10-a3e0ac23fc03",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "* Let's find the least useful feature using the *feature elimination* technique.\n",
    "* Train a model with all these features (using the same parameters as in Q4).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \n",
    "* Which of following feature has the smallest difference? \n",
    "   * **`total_rooms`**\n",
    "   * `total_bedrooms` \n",
    "   * `population`\n",
    "   * `households`\n",
    "\n",
    "> **note**: the difference doesn't have to be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9ac0f6-0f4d-4aa3-9d12-6425f152175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train_binarized)\n",
    "\n",
    "y_val_predicted = model.predict(X_val)\n",
    "acc_orig = accuracy_score(y_val_binarized, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffff57b7-13ff-4a02-8817-05e9304d13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_acc_dict = {}\n",
    "\n",
    "for feature in X_train.columns:\n",
    "    # Training\n",
    "    model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train.drop(feature, axis = 1), y_train_binarized)\n",
    "    \n",
    "    # Evaluating\n",
    "    y_val_predicted = model.predict(X_val.drop(feature, axis = 1))\n",
    "    diff_acc_dict[feature] = acc_orig - accuracy_score(y_val_binarized, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d94e15a-3bf7-4eef-80fe-af8e24face94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rooms                -0.000969\n",
       "x0_INLAND                  -0.000969\n",
       "x0_NEAR BAY                -0.000727\n",
       "rooms_per_household         0.000242\n",
       "x0_ISLAND                   0.000242\n",
       "x0_NEAR OCEAN               0.000242\n",
       "x0_<1H OCEAN                0.000484\n",
       "population_per_household    0.000969\n",
       "bedrooms_per_room           0.001211\n",
       "total_bedrooms              0.001453\n",
       "households                  0.002665\n",
       "longitude                   0.003149\n",
       "latitude                    0.003634\n",
       "housing_median_age          0.006056\n",
       "population                  0.010174\n",
       "median_income               0.050630\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(diff_acc_dict).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937181d-1b4e-4213-b516-8d36f7d639da",
   "metadata": {},
   "source": [
    "\n",
    "### Question 6\n",
    "\n",
    "* For this question, we'll see how to use a linear regression model from Scikit-Learn\n",
    "* We'll need to use the original column `'median_house_value'`. Apply the logarithmic transformation to this column.\n",
    "* Fit the Ridge regression model (`model = Ridge(alpha=a, solver=\"sag\", random_state=42)`) on the training data.\n",
    "* This model has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`\n",
    "* Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.\n",
    "\n",
    "If there are multiple options, select the smallest `alpha`.\n",
    "\n",
    "Options:\n",
    "- **0**\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b7e15da-bee1-4165-bfd2-3b5cdefb663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    error = y_pred - y\n",
    "    mse = (error ** 2).mean()\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82095be5-f3dd-4566-b3f8-b871ba55a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "y_test_log = np.log1p(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4583d7b-0d5b-4fe5-87fc-00efc51fa3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0 and RMSE = 0.524\n",
      "alpha = 0.01 and RMSE = 0.524\n",
      "alpha = 0.1 and RMSE = 0.524\n",
      "alpha = 1 and RMSE = 0.524\n",
      "alpha = 10 and RMSE = 0.524\n"
     ]
    }
   ],
   "source": [
    "for a in [0, 0.01, 0.1, 1, 10]:\n",
    "    model = Ridge(alpha=a, solver=\"sag\", random_state=42)\n",
    "    model.fit(X_train, y_train_log)\n",
    "    y_val_log_predicted = model.predict(X_val)\n",
    "    metric = rmse(y_val_log, y_val_log_predicted)\n",
    "    print(f\"alpha = {a} and RMSE = {round(metric, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbookcamp",
   "language": "python",
   "name": "mlbookcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
